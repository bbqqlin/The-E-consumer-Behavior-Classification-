install.packages("plyr", dependencies = T)
library(plyr)
library(readr)

# IMPORT DATASET#

#import survey dataset (Government Office Regions)
X5661SurveyofPersonalIncomes <- read_csv("~/Desktop/Data/5661SurveyofPersonalIncomes.csv")
X6988OpinionsSurveyInternetAccessModule <- read_csv("~/Desktop/Data/6988ONSOpinionsSurveyInternetAccessModule.csv")

#import dataset (LSOA)
IndexofMultipleDeprivation2015eng <- read_csv("~/Desktop/Data/IndexofMultipleDeprivation2015eng.csv")
DemoCen2011 <- read_csv("~/Desktop/Data/INITIAL.csv")

# DATA CLEANING #
# data perpration#
library(readr)
> data <- read_csv("C:/Users/bn16bl/Desktop/final/data.csv", 
                   +     col_types = cols(Netincomeafterhousingcosts = col_number(), 
                                          +         tax_i = col_number()))
View(data)
sapply(data, class)
sum(is.na(data))

lodata <- subset(data, Regionname == "London" )
ewdata <- subset(data, Regionname != "London")


lodata1 <- lodata[-1:-2]
lodata_use <- lodata1[-2:-11]

ewdata1 <- ewdata[-1:-2]
ewdata_use <- ewdata1[-2:-11]

sapply(lodata_use, class)
sapply(ewdata_use, class)

sum(is.na(lodata_use))
sum(is.na(ewdata_use))
                    
#aggregate(cbind(ewdata_use[-1])~LSOA11CD,ewdata_use,mean)

lo <- ddply(lodata_use,.(LSOA11CD),colwise(mean))
ew <- ddply(ewdata_use,.(LSOA11CD),colwise(mean))

sum(is.na(lo))
sum(is.na(ew))


write.csv(lo, "C:/Users/bn16bl/Downloads/lo.csv")
write.csv(ew, "C:/Users/bn16bl/Downloads/ew.csv")

############################################
#corellation# excel

colo <- cor(lo[-1],method = "pearson")
coew <- cor(ew[-1],method = "pearson")

test <- abline(lm(colo))
###################################################
ew0817 <- read_excel("C:/Users/bn16bl/Desktop/cor/ew0817.xlsx")
lo0818 <- read_excel("C:/Users/bn16bl/Desktop/cor/lo0818.xlsx")
#normalisation
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

loNorm <- as.data.frame(lapply(lo0818, normalize))
ewNorm <- as.data.frame(lapply(ew0817[-1], normalize))
sum(is.na(loNorm))
sum(is.na(ewNorm))
write.csv(loNorm, "C:/Users/bn16bl/Downloads/loNorm.csv")
write.csv(ewNorm, "C:/Users/bn16bl/Downloads/ewNorm.csv")




# Standardise variables #
sapply(cluster, class)
cluster$LSOA<-as.numeric(cluster$LSOA)
scalecluster<-scale(cluster)

###################################################
############## K-MEANS CLUSTERING #################
###################################################
# Elbow plot for best number of clusters - below #
set.seed(123)
k.max <- 15
data <- scalecluster
wss <- sapply(1:k.max,
              function(k){kmeans(data, k, nstart=50 )$tot.withinss})
plot(1:k.max, wss, type="b", pch = 19, frame = FALSE, xlab="Number of clusters K", ylab="Total within-clusters sum of squares")
abline(v = 3, lty =2)

# Fit k means (Number is K). Starting point. Okay, now that we have seen the data, let us try to cluster it. Since the initial cluster assignments are random, let us set the seed to ensure reproducibility.
set.seed(20)
irisCluster <- kmeans(iris[, 3:4], 3, nstart = 20)


#Split/subset a data frame by factors in Government Office Regions column 

5661list <- split(X5661SurveyofPersonalIncomes, X5661SurveyofPersonalIncomes$GORA)
6988list <- split(X6988OpinionsSurveyInternetAccessModule, X6988OpinionsSurveyInternetAccessModule$GORCODE)

#Merge the dataset by region

total <- merge(5661list, 6988list,by="ID")
